filter(state == state_name) %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- end_non_partitioned - start_non_partitioned
# Partitioned Parquet
start_partitioned <- Sys.time()
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
partitioned_summary <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- end_partitioned - start_partitioned
time_difference <- time_non_partitioned - time_partitioned
cat("Time using non-partitioned data:", time_non_partitioned, "seconds\n")
cat("Time using partitioned data:", time_partitioned, "seconds\n")
cat("Time difference:", time_difference, "seconds\n")
list(
non_partitioned_summary = non_partitioned_summary,
partitioned_summary = partitioned_summary
)
}
sample_test <- comparison_partitioned_non_partitioned(
state_name = "CA",
csv_data = combined_df,
partitioned_path = partitioned_path
)
csv_dir <- readline(prompt = "Enter the path to the folder containing the unzipped CSV files: ")
csv_files <- list.files(path = csv_dir, pattern = "\\.csv$", full.names = TRUE)
read_csv_with_fallback <- function(file) {
read_csv(
file,
col_types = cols(.default = col_character())
)
}
combined_df <- csv_files %>%
map_dfr(read_csv_with_fallback)
comparison_partitioned_non_partitioned <- function(state_name, csv_data, partitioned_path) {
#Non partitioned CSV
start_non_partitioned <- Sys.time()
non_partitioned_summary <- csv_data %>%
filter(state == state_name) %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- end_non_partitioned - start_non_partitioned
# Partitioned Parquet
start_partitioned <- Sys.time()
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
partitioned_summary <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- end_partitioned - start_partitioned
time_difference <- time_non_partitioned - time_partitioned
cat("Time using non-partitioned data:", time_non_partitioned, "seconds\n")
cat("Time using partitioned data:", time_partitioned, "seconds\n")
cat("Time difference:", time_difference, "seconds\n")
list(
non_partitioned_summary = non_partitioned_summary,
partitioned_summary = partitioned_summary
)
}
sample_test <- comparison_partitioned_non_partitioned(
state_name = "CA",
csv_data = combined_df,
partitioned_path = partitioned_path
)
csv_dir <- readline(prompt = "Enter the path to the folder containing the unzipped CSV files: ")
csv_files <- list.files(path = csv_dir, pattern = "\\.csv$", full.names = TRUE)
read_csv_with_fallback <- function(file) {
read_csv(
file,
col_types = cols(.default = col_character())
)
}
combined_df <- csv_files %>%
map_dfr(read_csv_with_fallback)
comparison_partitioned_non_partitioned <- function(state_name, csv_data, partitioned_path) {
#Non partitioned CSV
start_non_partitioned <- Sys.time()
non_partitioned_summary <- csv_data %>%
filter(state == state_name) %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- end_non_partitioned - start_non_partitioned
# Partitioned Parquet
start_partitioned <- Sys.time()
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
partitioned_summary <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- end_partitioned - start_partitioned
time_difference <- time_non_partitioned - time_partitioned
cat("Time using non-partitioned data:", time_non_partitioned, "seconds\n")
cat("Time using partitioned data:", time_partitioned, "seconds\n")
cat("Time difference:", time_difference, "seconds\n")
list(
non_partitioned_summary = non_partitioned_summary,
partitioned_summary = partitioned_summary
)
}
sample_test <- comparison_partitioned_non_partitioned(
state_name = "CA",
csv_data = combined_df,
partitioned_path = partitioned_path
)
View(combined_df)
sample_test <- comparison_partitioned_non_partitioned(
state_name = "WY",
csv_data = combined_df,
partitioned_path = partitioned_path
)
comparison_partitioned_non_partitioned <- function(state_name, csv_data, partitioned_path) {
#Non partitioned CSV
csv_arrow_table <- as_arrow_table(csv_data)
start_non_partitioned <- Sys.time()
non_partitioned_summary <- csv_arrow_table %>%
filter(state == state_name) %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- end_non_partitioned - start_non_partitioned
# Partitioned Parquet
start_partitioned <- Sys.time()
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
partitioned_summary <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- end_partitioned - start_partitioned
time_difference <- time_non_partitioned - time_partitioned
cat("Time using non-partitioned data:", time_non_partitioned, "seconds\n")
cat("Time using partitioned data:", time_partitioned, "seconds\n")
cat("Time difference:", time_difference, "seconds\n")
list(
non_partitioned_summary = non_partitioned_summary,
partitioned_summary = partitioned_summary
)
}
sample_test <- comparison_partitioned_non_partitioned(
state_name = "WY",
csv_data = combined_df,
partitioned_path = partitioned_path
)
sample_test <- comparison_partitioned_non_partitioned(
state_name = "UT",
csv_data = combined_df,
partitioned_path = partitioned_path
)
unique_states <- unique(combined_df$state)
print(unique_sta)
print(unique_states)
View(combined_df)
unique_states <- unique(combined_df$state)
results <- data.frame(
state = character(),
num_observations = numeric(),
speed_ratio = numeric(),
stringsAsFactors = FALSE
)
for (state_name in unique_states) {
csv_arrow_table <- as_arrow_table(combined_df)
start_non_partitioned <- Sys.time()
filtered_non_partitioned <- csv_arrow_table %>% filter(state == state_name)
non_partitioned_summary <- filtered_non_partitioned %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- end_non_partitioned - start_non_partitioned
# Partitioned data
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
start_partitioned <- Sys.time()
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
filtered_partitioned <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- end_partitioned - start_partitioned
# Calculate metrics
num_observations <- nrow(as.data.frame(filtered_non_partitioned))
speed_ratio <- as.numeric(time_non_partitioned / time_partitioned)
# Append results
results <- rbind(
results,
data.frame(
state = state_name,
num_observations = num_observations,
speed_ratio = speed_ratio
)
)
}
unique_states <- unique(combined_df$state)
results <- data.frame(
state = character(),
num_observations = numeric(),
speed_ratio = numeric(),
stringsAsFactors = FALSE
)
for (state_name in unique_states) {
csv_arrow_table <- as_arrow_table(combined_df)
start_non_partitioned <- Sys.time()
filtered_non_partitioned <- csv_arrow_table %>% filter(state == state_name)
non_partitioned_summary <- filtered_non_partitioned %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- as.numeric(end_non_partitioned - start_non_partitioned, units = "secs")
# Partitioned data
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
start_partitioned <- Sys.time()
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
filtered_partitioned <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- as.numeric(end_partitioned - start_partitioned, units = "secs")
# Calculate metrics
num_observations <- nrow(as.data.frame(filtered_non_partitioned))
speed_ratio <- as.numeric(time_non_partitioned / time_partitioned)
# Append results
results <- rbind(
results,
data.frame(
state = state_name,
num_observations = num_observations,
speed_ratio = speed_ratio
)
)
}
View(results)
plot <- ggplot(results, aes(x = num_observations, y = speed_ratio)) +
geom_point() +
labs(
title = "Partitioned Speedup vs. Filtered Data Size",
x = "Number of Observations (Filtered Data)",
y = "Speed Improvement (Non-Partitioned Time / Partitioned Time)"
) +
theme_minimal()
print(plot)
png("scatter_plot_partitioned_speedup.png", width = 800, height = 600)
print(plot)
dev.off()
print(plot)
dev.off()
png("scatter_plot_partitioned_speedup.png", width = 800, height = 600)
print(plot)
csv_dir <- readline(prompt = "Enter the path to the folder containing the unzipped CSV files: ")
csv_files <- list.files(path = csv_dir, pattern = "\\.csv$", full.names = TRUE)
read_csv_with_fallback <- function(file) {
read_csv(
file,
col_types = cols(.default = col_character())
)
}
combined_df <- csv_files %>%
map_dfr(read_csv_with_fallback)
library(arrow)
library(tidyverse)
csv_files <- list.files(path = csv_dir, pattern = "\\.csv$", full.names = TRUE)
read_csv_with_fallback <- function(file) {
read_csv(
file,
col_types = cols(.default = col_character())
)
}
combined_df <- csv_files %>%
map_dfr(read_csv_with_fallback)
csv_dir <- readline(prompt = "Enter the path to the folder containing the unzipped CSV files: ")
library(tidyverse)
library(arrow)
library(tidyverse)
csv_dir <- readline(prompt = "Enter the path to the folder containing the unzipped CSV files: ")
csv_dir <- readline(prompt = "Enter the path to the folder containing the unzipped CSV files: ")
csv_files <- list.files(path = csv_dir, pattern = "\\.csv$", full.names = TRUE)
read_csv_with_fallback <- function(file) {
read_csv(
file,
col_types = cols(.default = col_character())
)
}
combined_df <- csv_files %>%
map_dfr(read_csv_with_fallback)
parquet_path <- readline(prompt = "Enter the path where you want to save the combined Parquet file: ")
write_parquet(combined_df, sink = file.path(parquet_path, "combined.parquet"))
partitioned_path <- readline(prompt = "Enter the path where you want to save the partitioned Parquet files: ")
if (!"state" %in% colnames(combined_df)) {
stop("The 'state' column is not present in the dataset. Check your CSV files.")
}
combined_df %>%
group_by(state) %>%
write_dataset(
path = partitioned_path,
format = "parquet",
partitioning = "state"
)
partioned_dataset <- open_dataset(partitioned_path, format = "parquet")
parquet_files <- list.files(
path = partitioned_path,
pattern = "\\.parquet$",
full.names = TRUE,
recursive = TRUE
)
partioned_dataset <- open_dataset(partitioned_path, format = "parquet")
parquet_files <- list.files(
path = partitioned_path,
pattern = "\\.parquet$",
full.names = TRUE,
recursive = TRUE
)
partioned_dataset <- open_dataset(partitioned_files, format = "parquet")
partioned_dataset <- open_dataset(parquet_files, format = "parquet")
print(partioned_dataset)
comparison_partitioned_non_partitioned <- function(state_name, csv_data, partitioned_path) {
#Non partitioned CSV
csv_arrow_table <- as_arrow_table(csv_data)
start_non_partitioned <- Sys.time()
non_partitioned_summary <- csv_arrow_table %>%
filter(state == state_name) %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- end_non_partitioned - start_non_partitioned
# Partitioned Parquet
start_partitioned <- Sys.time()
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
partitioned_summary <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- end_partitioned - start_partitioned
time_difference <- time_non_partitioned - time_partitioned
cat("Time using non-partitioned data:", time_non_partitioned, "seconds\n")
cat("Time using partitioned data:", time_partitioned, "seconds\n")
cat("Time difference:", time_difference, "seconds\n")
list(
non_partitioned_summary = non_partitioned_summary,
partitioned_summary = partitioned_summary
)
}
sample_test <- comparison_partitioned_non_partitioned(
state_name = "UT",
csv_data = combined_df,
partitioned_path = partitioned_path
)
unique_states <- unique(combined_df$state)
results <- data.frame(
state = character(),
num_observations = numeric(),
speed_ratio = numeric(),
stringsAsFactors = FALSE
)
for (state_name in unique_states) {
csv_arrow_table <- as_arrow_table(combined_df)
start_non_partitioned <- Sys.time()
filtered_non_partitioned <- csv_arrow_table %>% filter(state == state_name)
non_partitioned_summary <- filtered_non_partitioned %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- as.numeric(end_non_partitioned - start_non_partitioned, units = "secs")
# Partitioned data
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
start_partitioned <- Sys.time()
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
filtered_partitioned <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- as.numeric(end_partitioned - start_partitioned, units = "secs")
num_observations <- nrow(as.data.frame(filtered_non_partitioned))
speed_ratio <- as.numeric(time_non_partitioned / time_partitioned)
results <- rbind(
results,
data.frame(
state = state_name,
num_observations = num_observations,
speed_ratio = speed_ratio
)
)
}
unique_states <- unique(combined_df$state)
results <- data.frame(
state = character(),
num_observations = numeric(),
speed_ratio = numeric(),
stringsAsFactors = FALSE
)
unique_states <- unique(combined_df$state)
results <- data.frame(
state = character(),
num_observations = numeric(),
speed_ratio = numeric(),
stringsAsFactors = FALSE
)
for (state_name in unique_states) {
csv_arrow_table <- as_arrow_table(combined_df)
start_non_partitioned <- Sys.time()
filtered_non_partitioned <- csv_arrow_table %>% filter(state == state_name)
non_partitioned_summary <- filtered_non_partitioned %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_non_partitioned <- Sys.time()
time_non_partitioned <- as.numeric(end_non_partitioned - start_non_partitioned, units = "secs")
# Partitioned data
state_partition_path <- file.path(partitioned_path, paste0("state=", state_name))
start_partitioned <- Sys.time()
partitioned_data <- open_dataset(state_partition_path, format = "parquet")
filtered_partitioned <- partitioned_data %>%
group_by(scope_severity) %>%
summarise(num_deficiencies = n(), .groups = "drop")
end_partitioned <- Sys.time()
time_partitioned <- as.numeric(end_partitioned - start_partitioned, units = "secs")
num_observations <- nrow(as.data.frame(filtered_non_partitioned))
speed_ratio <- as.numeric(time_non_partitioned / time_partitioned)
results <- rbind(
results,
data.frame(
state = state_name,
num_observations = num_observations,
speed_ratio = speed_ratio
)
)
}
plot <- ggplot(results, aes(x = num_observations, y = speed_ratio)) +
geom_point() +
labs(
title = "Partitioned Speedup vs. Filtered Data Size",
x = "Number of Observations (Filtered Data)",
y = "Speed Improvement (Non-Partitioned Time / Partitioned Time)"
) +
theme_minimal()
png("scatter_plot_partitioned_speedup.png", width = 800, height = 600)
print(plot)
print(plot)
View(plot)
plot
plot
view(plot)
View(results)
plot <- ggplot(results, aes(x = num_observations, y = speed_ratio)) +
geom_point() +
labs(
title = "Partitioned Speedup vs. Filtered Data Size",
x = "Number of Observations (Filtered Data)",
y = "Speed Improvement (Non-Partitioned Time / Partitioned Time)"
) +
theme_minimal()
print(plot)
plot <- ggplot(results, aes(x = num_observations, y = speed_ratio)) +
geom_point() +
labs(
title = "Partitioned Speedup vs. Filtered Data Size",
x = "Number of Observations (Filtered Data)",
y = "Speed Improvement (Non-Partitioned Time / Partitioned Time)"
) +
theme_minimal()
png("scatter_plot_partitioned_speedup.png", width = 800, height = 600)
print(plot)
View(results)
plot <- ggplot(results, aes(x = num_observations, y = speed_ratio)) +
geom_point() +
labs(
title = "Partitioned Speedup vs. Filtered Data Size",
x = "Number of Observations (Filtered Data)",
y = "Speed Improvement (Non-Partitioned Time / Partitioned Time)"
) +
theme_minimal()
# Save the plot as a .png
png("scatter_plot_partitioned_speedup.png", width = 800, height = 600)
print(plot)
dev.off()
library(tidyverse)
plot <- ggplot(results, aes(x = num_observations, y = speed_ratio)) +
geom_point() +
labs(
title = "Partitioned Speedup vs. Filtered Data Size",
x = "Number of Observations (Filtered Data)",
y = "Speed Improvement (Non-Partitioned Time / Partitioned Time)"
) +
theme_minimal()
# Save the plot as a .png
png("scatter_plot_partitioned_speedup.png", width = 800, height = 600)
print(plot)
View(filtered_non_partitioned)
View(filtered_partitioned)
View(non_partitioned_summary)
View(plot)
View(sample_test)
View(results)
# Create the plot
plot <- ggplot(results, aes(x = num_observations, y = speed_ratio)) +
geom_point() +
labs(
title = "Partitioned Speedup vs. Filtered Data Size",
x = "Number of Observations (Filtered Data)",
y = "Speed Improvement (Non-Partitioned Time / Partitioned Time)"
) +
theme_minimal()
# Save the plot as a PNG
png("scatter_plot_partitioned_speedup.png", width = 800, height = 600)
print(plot)  # Save the plot
dev.off()    # Close the graphical device
# Display the plot in the console or RStudio
print(plot)
